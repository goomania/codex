{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d169f24",
   "metadata": {},
   "source": [
    "# Cloud Computing Week Demo\n",
    "\n",
    "This notebook contains short demonstrations and explanations for each topic in this week's cloud computing module. Every code cell is paired with a markdown description so you can walk through the concepts during a live session or self-paced review."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61dd2d1e",
   "metadata": {},
   "source": [
    "## 2.1 Cloud Computing History\n",
    "The following code assembles a short timeline of major milestones that led to modern cloud computing. Use it to introduce the evolution from time-sharing mainframes to today's serverless platforms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9804d143",
   "metadata": {},
   "outputs": [],
   "source": [
    "events = [\n",
    "    (\"1960s\", \"Mainframe time-sharing enables multiple users to share expensive computing resources.\"),\n",
    "    (\"1990s\", \"Early application service providers deliver software over the internet.\"),\n",
    "    (\"2006\", \"Amazon Web Services launches EC2 and S3, marking the start of mainstream IaaS.\"),\n",
    "    (\"2010s\", \"Cloud-native architectures, containers, and DevOps accelerate cloud adoption.\"),\n",
    "    (\"2020s\", \"Serverless, edge computing, and AI services become foundational cloud offerings.\"),\n",
    "]\n",
    "\n",
    "for period, milestone in events:\n",
    "    print(f\"{period:<8} - {milestone}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f2cec0",
   "metadata": {},
   "source": [
    "## 2.2 Defining Cloud Computing\n",
    "This example contrasts an on-premises deployment with a cloud-based alternative. It highlights how elasticity and pay-as-you-go pricing affect the total monthly cost of a workload."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5ee6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import List\n",
    "\n",
    "@dataclass\n",
    "class DeploymentOption:\n",
    "    name: str\n",
    "    base_monthly_cost: float\n",
    "    cost_per_hour: float\n",
    "\n",
    "    def monthly_cost(self, usage_hours: List[float]) -> float:\n",
    "        variable = sum(hours * self.cost_per_hour for hours in usage_hours)\n",
    "        return self.base_monthly_cost + variable\n",
    "\n",
    "workload_hours = [120, 140, 160, 130]  # Weekly usage hours over a month\n",
    "on_prem = DeploymentOption(\"On-Premises\", base_monthly_cost=2800, cost_per_hour=2.5)\n",
    "cloud = DeploymentOption(\"Cloud\", base_monthly_cost=500, cost_per_hour=4.0)\n",
    "\n",
    "for option in (on_prem, cloud):\n",
    "    cost = option.monthly_cost(workload_hours)\n",
    "    print(f\"{option.name:12}: ${cost:,.2f}\")\n",
    "\n",
    "savings = on_prem.monthly_cost(workload_hours) - cloud.monthly_cost(workload_hours)\n",
    "print(f\"Monthly savings with cloud: ${savings:,.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b654fc",
   "metadata": {},
   "source": [
    "## 2.3 Virtualization\n",
    "Virtualization slices a physical host into multiple isolated virtual machines. The snippet below emulates a hypervisor that provisions VMs and tracks resource allocation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff4134c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "from typing import Dict\n",
    "\n",
    "@dataclass\n",
    "class VirtualMachine:\n",
    "    name: str\n",
    "    vcpu: int\n",
    "    memory_gb: int\n",
    "\n",
    "@dataclass\n",
    "class Hypervisor:\n",
    "    total_vcpu: int\n",
    "    total_memory_gb: int\n",
    "    vms: Dict[str, VirtualMachine] = field(default_factory=dict)\n",
    "\n",
    "    def allocate_vm(self, vm: VirtualMachine) -> bool:\n",
    "        if self.available_vcpu() >= vm.vcpu and self.available_memory() >= vm.memory_gb:\n",
    "            self.vms[vm.name] = vm\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def available_vcpu(self) -> int:\n",
    "        used = sum(vm.vcpu for vm in self.vms.values())\n",
    "        return self.total_vcpu - used\n",
    "\n",
    "    def available_memory(self) -> int:\n",
    "        used = sum(vm.memory_gb for vm in self.vms.values())\n",
    "        return self.total_memory_gb - used\n",
    "\n",
    "    def utilization_snapshot(self) -> Dict[str, int]:\n",
    "        return {\n",
    "            \"allocated_vcpu\": self.total_vcpu - self.available_vcpu(),\n",
    "            \"allocated_memory_gb\": self.total_memory_gb - self.available_memory(),\n",
    "        }\n",
    "\n",
    "host = Hypervisor(total_vcpu=32, total_memory_gb=128)\n",
    "\n",
    "for vm in [\n",
    "    VirtualMachine(\"web\", vcpu=4, memory_gb=16),\n",
    "    VirtualMachine(\"api\", vcpu=8, memory_gb=32),\n",
    "    VirtualMachine(\"analytics\", vcpu=12, memory_gb=48),\n",
    "]:\n",
    "    success = host.allocate_vm(vm)\n",
    "    print(f\"Provisioning {vm.name:10}: {'success' if success else 'insufficient capacity'}\")\n",
    "\n",
    "print(\"Remaining capacity:\", host.available_vcpu(), \"vCPU,\", host.available_memory(), \"GB RAM\")\n",
    "print(\"Utilization snapshot:\", host.utilization_snapshot())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec70b0e",
   "metadata": {},
   "source": [
    "## 2.4 Economies of Scale\n",
    "Cloud providers lower unit costs as demand grows. The code computes the cost per 10,000 requests at different traffic scales to visualize economies of scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4b7900",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_per_unit(fixed_cost: float, variable_cost: float, requests: int) -> float:\n",
    "    total_cost = fixed_cost + variable_cost * requests\n",
    "    return total_cost / (requests / 10_000)\n",
    "\n",
    "traffic_levels = [50_000, 100_000, 500_000, 1_000_000]\n",
    "fixed = 1200\n",
    "variable = 0.0025\n",
    "\n",
    "for requests in traffic_levels:\n",
    "    cpu = cost_per_unit(fixed, variable, requests)\n",
    "    print(f\"{requests:>8,} requests -> ${cpu:,.2f} per 10k requests\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cef9e0f",
   "metadata": {},
   "source": [
    "## 2.5 Obstacles to Cloud Computing\n",
    "Security, compliance, and organizational readiness all influence adoption. This snippet models a lightweight risk score and suggests mitigations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2912ebe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "obstacles = {\n",
    "    \"Security\": 0.8,\n",
    "    \"Compliance\": 0.6,\n",
    "    \"Vendor Lock-In\": 0.5,\n",
    "    \"Skill Gaps\": 0.7,\n",
    "}\n",
    "\n",
    "mitigations = {\n",
    "    \"Security\": \"Adopt zero-trust controls and continuous monitoring.\",\n",
    "    \"Compliance\": \"Map regulatory controls to shared responsibility models.\",\n",
    "    \"Vendor Lock-In\": \"Design with open standards and multi-cloud abstractions.\",\n",
    "    \"Skill Gaps\": \"Invest in training and adopt managed services where possible.\",\n",
    "}\n",
    "\n",
    "for name, severity in sorted(obstacles.items(), key=lambda item: item[1], reverse=True):\n",
    "    print(f\"{name:13} risk score: {severity:.1f} -> {mitigations[name]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf82a16",
   "metadata": {},
   "source": [
    "## 2.6 Elasticity\n",
    "Elastic systems right-size infrastructure as demand fluctuates. The example scales application instances up or down in response to incoming request volume."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcda180e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import ceil\n",
    "\n",
    "request_profile = [120, 250, 430, 390, 210, 160]\n",
    "capacity_per_instance = 120\n",
    "\n",
    "instance_plan = []\n",
    "for minute, requests in enumerate(request_profile, start=1):\n",
    "    instances_needed = max(1, ceil(requests / capacity_per_instance))\n",
    "    instance_plan.append(instances_needed)\n",
    "    print(f\"Minute {minute}: {requests:3d} requests -> {instances_needed} instance(s)\")\n",
    "\n",
    "print(\"Total instance-minutes consumed:\", sum(instance_plan))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe28750",
   "metadata": {},
   "source": [
    "## 2.7 Amazon EC2 and S3 (Conceptual Demo)\n",
    "Without real AWS credentials we can still estimate costs. The code approximates a simple architecture using EC2 compute and S3 storage to show how usage drives monthly spend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ba1692",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class EC2Instance:\n",
    "    instance_type: str\n",
    "    hourly_rate: float\n",
    "    hours_per_month: int\n",
    "\n",
    "    def monthly_cost(self) -> float:\n",
    "        return self.hourly_rate * self.hours_per_month\n",
    "\n",
    "@dataclass\n",
    "class S3Bucket:\n",
    "    storage_gb: float\n",
    "    storage_price_per_gb: float\n",
    "    requests_per_month: int\n",
    "    request_price_per_1k: float\n",
    "\n",
    "    def monthly_cost(self) -> float:\n",
    "        storage_cost = self.storage_gb * self.storage_price_per_gb\n",
    "        request_cost = (self.requests_per_month / 1000) * self.request_price_per_1k\n",
    "        return storage_cost + request_cost\n",
    "\n",
    "ec2 = EC2Instance(\"t3.medium\", hourly_rate=0.0416, hours_per_month=24 * 30)\n",
    "s3 = S3Bucket(storage_gb=250, storage_price_per_gb=0.023, requests_per_month=800_000, request_price_per_1k=0.0004)\n",
    "\n",
    "total_cost = ec2.monthly_cost() + s3.monthly_cost()\n",
    "print(f\"EC2 monthly estimate: ${ec2.monthly_cost():.2f}\")\n",
    "print(f\"S3 monthly estimate:  ${s3.monthly_cost():.2f}\")\n",
    "print(f\"Combined architecture: ${total_cost:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8adc0fc2",
   "metadata": {},
   "source": [
    "## 2.8 The Business of Cloud Computing\n",
    "Cloud business models balance subscription revenue with infrastructure and support costs. The code projects annual gross margin under different pricing strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38bef5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def project_margin(customers: int, price_per_customer: float, infra_cost_per_customer: float, support_cost_per_customer: float) -> float:\n",
    "    revenue = customers * price_per_customer\n",
    "    cost = customers * (infra_cost_per_customer + support_cost_per_customer)\n",
    "    return revenue - cost\n",
    "\n",
    "scenarios = [\n",
    "    {\"customers\": 500, \"price\": 49, \"infra\": 12, \"support\": 8},\n",
    "    {\"customers\": 500, \"price\": 59, \"infra\": 12, \"support\": 10},\n",
    "    {\"customers\": 750, \"price\": 45, \"infra\": 11, \"support\": 9},\n",
    "]\n",
    "\n",
    "for scenario in scenarios:\n",
    "    margin = project_margin(\n",
    "        scenario[\"customers\"],\n",
    "        scenario[\"price\"],\n",
    "        scenario[\"infra\"],\n",
    "        scenario[\"support\"],\n",
    "    )\n",
    "    print(\n",
    "        f\"Customers: {scenario['customers']:3d}, Price: ${scenario['price']:>2} -> Annual gross margin: ${margin:,.0f}\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abec17ff",
   "metadata": {},
   "source": [
    "## 2.9 Big Data Requires Parallel Computing\n",
    "Large log datasets benefit from parallel processing. This demo splits log data into chunks and uses a thread pool to count errors concurrently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871df6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import random\n",
    "\n",
    "random.seed(7)\n",
    "\n",
    "levels = [\"INFO\", \"DEBUG\", \"WARN\", \"ERROR\"]\n",
    "log_lines = [random.choice(levels) for _ in range(50_000)]\n",
    "chunk_size = 5_000\n",
    "\n",
    "\n",
    "def count_errors(chunk):\n",
    "    return sum(1 for entry in chunk if entry == \"ERROR\")\n",
    "\n",
    "\n",
    "chunks = [log_lines[i : i + chunk_size] for i in range(0, len(log_lines), chunk_size)]\n",
    "with ThreadPoolExecutor(max_workers=4) as executor:\n",
    "    error_counts = list(executor.map(count_errors, chunks))\n",
    "\n",
    "print(\"Chunk-level error counts:\", error_counts)\n",
    "print(\"Total errors detected:\", sum(error_counts))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f52b4e",
   "metadata": {},
   "source": [
    "## 2.10 MapReduce Example: Word Count\n",
    "MapReduce splits work into map and reduce phases. The code below tokenizes documents, emits intermediate key-value pairs, and then reduces them into a global word count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d9e2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import re\n",
    "\n",
    "documents = [\n",
    "    \"Cloud computing enables elastic scaling of resources.\",\n",
    "    \"MapReduce is a programming model for processing large datasets in the cloud.\",\n",
    "    \"Elastic workloads benefit from distributed systems like MapReduce.\",\n",
    "]\n",
    "\n",
    "word_pattern = re.compile(r\"[A-Za-z']+\")\n",
    "\n",
    "intermediate = defaultdict(list)\n",
    "for doc in documents:\n",
    "    for match in word_pattern.findall(doc.lower()):\n",
    "        intermediate[match].append(1)\n",
    "\n",
    "word_counts = {word: sum(counts) for word, counts in intermediate.items()}\n",
    "for word, count in sorted(word_counts.items()):\n",
    "    if count > 1:\n",
    "        print(f\"{word:12}: {count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66121078",
   "metadata": {},
   "source": [
    "## 2.11 General Form of a MapReduce Task\n",
    "This reusable helper mirrors the generic MapReduce contract. Provide any map and reduce functions to process structured datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e7a7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from statistics import mean\n",
    "from typing import Callable, Iterable, Any, Dict, List, Tuple\n",
    "\n",
    "MapFn = Callable[[Any], Iterable[Tuple[str, Any]]]\n",
    "ReduceFn = Callable[[str, List[Any]], Any]\n",
    "\n",
    "\n",
    "def map_reduce(dataset: Iterable[Any], map_fn: MapFn, reduce_fn: ReduceFn) -> Dict[str, Any]:\n",
    "    grouped: Dict[str, List[Any]] = defaultdict(list)\n",
    "    for item in dataset:\n",
    "        for key, value in map_fn(item):\n",
    "            grouped[key].append(value)\n",
    "    return {key: reduce_fn(key, values) for key, values in grouped.items()}\n",
    "\n",
    "\n",
    "requests = [\n",
    "    {\"service\": \"auth\", \"duration_ms\": 120},\n",
    "    {\"service\": \"auth\", \"duration_ms\": 140},\n",
    "    {\"service\": \"payments\", \"duration_ms\": 220},\n",
    "    {\"service\": \"payments\", \"duration_ms\": 260},\n",
    "    {\"service\": \"search\", \"duration_ms\": 95},\n",
    "]\n",
    "\n",
    "\n",
    "def request_mapper(event):\n",
    "    yield event[\"service\"], event[\"duration_ms\"]\n",
    "\n",
    "\n",
    "def average_reducer(service, durations):\n",
    "    return round(mean(durations), 1)\n",
    "\n",
    "average_latency = map_reduce(requests, request_mapper, average_reducer)\n",
    "print(\"Average latency per service:\")\n",
    "for service, latency in average_latency.items():\n",
    "    print(f\"  {service:9} -> {latency} ms\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87870b4",
   "metadata": {},
   "source": [
    "## 2.12 Hash Functions and Hash Tables\n",
    "Hash tables support quick lookups in distributed systems. The class below implements open addressing with linear probing to highlight collision handling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbeebc39",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HashTable:\n",
    "    def __init__(self, size: int = 8):\n",
    "        self.size = size\n",
    "        self.keys = [None] * size\n",
    "        self.values = [None] * size\n",
    "\n",
    "    def _hash(self, key: str) -> int:\n",
    "        return sum(ord(ch) for ch in key) % self.size\n",
    "\n",
    "    def insert(self, key: str, value):\n",
    "        index = self._hash(key)\n",
    "        start_index = index\n",
    "        while self.keys[index] not in (None, key):\n",
    "            index = (index + 1) % self.size\n",
    "            if index == start_index:\n",
    "                raise RuntimeError(\"Hash table is full\")\n",
    "        self.keys[index] = key\n",
    "        self.values[index] = value\n",
    "\n",
    "    def get(self, key: str):\n",
    "        index = self._hash(key)\n",
    "        start_index = index\n",
    "        while self.keys[index] is not None:\n",
    "            if self.keys[index] == key:\n",
    "                return self.values[index]\n",
    "            index = (index + 1) % self.size\n",
    "            if index == start_index:\n",
    "                break\n",
    "        raise KeyError(key)\n",
    "\n",
    "\n",
    "routing_table = HashTable(size=10)\n",
    "routing_table.insert(\"api-server\", {\"ip\": \"10.0.0.5\"})\n",
    "routing_table.insert(\"worker-01\", {\"ip\": \"10.0.0.21\"})\n",
    "routing_table.insert(\"worker-02\", {\"ip\": \"10.0.0.22\"})\n",
    "\n",
    "print(\"Lookup api-server ->\", routing_table.get(\"api-server\"))\n",
    "print(\"Lookup worker-02 ->\", routing_table.get(\"worker-02\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0613bd3b",
   "metadata": {},
   "source": [
    "## 2.13 MapReduce Details\n",
    "Combiners reduce shuffle volume by aggregating mapper outputs locally. The snippet compares raw mapper emissions with the optimized combiner workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3166190",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [\n",
    "    \"server1 ERROR disk full\",\n",
    "    \"server2 INFO ok\",\n",
    "    \"server1 ERROR disk full\",\n",
    "    \"server3 WARN latency\",\n",
    "]\n",
    "\n",
    "\n",
    "def mapper(log_line):\n",
    "    server, level, *_ = log_line.split()\n",
    "    yield (server, 1)\n",
    "\n",
    "\n",
    "def combiner(emissions):\n",
    "    partial = defaultdict(int)\n",
    "    for key, value in emissions:\n",
    "        partial[key] += value\n",
    "    return list(partial.items())\n",
    "\n",
    "\n",
    "# Mapper emissions without combiner\n",
    "raw_emissions = [emission for line in documents for emission in mapper(line)]\n",
    "print(\"Raw mapper emissions:\", raw_emissions)\n",
    "\n",
    "# With combiner applied per document source (e.g., per server)\n",
    "combined = []\n",
    "for server in {line.split()[0] for line in documents}:\n",
    "    server_lines = [line for line in documents if line.startswith(server)]\n",
    "    emissions = [emission for line in server_lines for emission in mapper(line)]\n",
    "    combined.extend(combiner(emissions))\n",
    "\n",
    "print(\"After combiner (reduced shuffle):\", combined)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da919d3f",
   "metadata": {},
   "source": [
    "## 2.14 MapReduce Details (Partitioning)\n",
    "Partitioners decide which reducer processes each key. Here, keys are routed based on their first letter to simulate custom partitioning strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e84c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def partitioner(key: str, num_reducers: int) -> int:\n",
    "    return (ord(key[0].lower()) - ord('a')) % num_reducers\n",
    "\n",
    "keys = [\"alpha\", \"beta\", \"gamma\", \"delta\", \"epsilon\", \"zeta\"]\n",
    "assignments = {key: partitioner(key, num_reducers=3) for key in keys}\n",
    "\n",
    "print(\"Reducer assignments:\")\n",
    "for key, reducer_id in assignments.items():\n",
    "    print(f\"  Key '{key}' -> reducer {reducer_id}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6582853",
   "metadata": {},
   "source": [
    "## 2.15 MapReduce Implementation in Hadoop\n",
    "While Hadoop jobs run on Java, we can simulate the execution flow in Python. The code prints a simplified sequence of Hadoop job stages along with configuration parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8986b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_steps = [\n",
    "    \"1. Client submits job configuration to ResourceManager\",\n",
    "    \"2. Input data is split and distributed across HDFS blocks\",\n",
    "    \"3. Map tasks execute on DataNodes close to the data\",\n",
    "    \"4. Intermediate output is shuffled and sorted\",\n",
    "    \"5. Reduce tasks aggregate results and write to HDFS\",\n",
    "    \"6. Job history is recorded for monitoring and auditing\",\n",
    "]\n",
    "\n",
    "for step in job_steps:\n",
    "    print(step)\n",
    "\n",
    "job_configuration = {\n",
    "    \"mapreduce.job.reduces\": 4,\n",
    "    \"mapreduce.input.fileinputformat.split.maxsize\": \"128MB\",\n",
    "    \"mapreduce.output.fileoutputformat.compress\": True,\n",
    "}\n",
    "\n",
    "print()  # Add a blank line before showing configuration values\n",
    "print(\"Sample Hadoop configuration parameters:\")\n",
    "for key, value in job_configuration.items():\n",
    "    print(f\"  {key}: {value}\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
