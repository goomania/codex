{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d9bf66c",
   "metadata": {},
   "source": [
    "# Computer Vision Mini Exercises\n",
    "\n",
    "This notebook guides you through a set of mini exercises that demonstrate common computer vision workflows using both **PyTorch** and **TensorFlow**. Each section includes explanations, runnable code, and short practice prompts that you can use in class to reinforce the concepts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6965d95b",
   "metadata": {},
   "source": [
    "## Learning Objectives\n",
    "\n",
    "By the end of this lab, students should be able to:\n",
    "\n",
    "* Load and inspect an image classification dataset.\n",
    "* Build and train a simple convolutional neural network (CNN) in PyTorch.\n",
    "* Build and train an equivalent CNN in TensorFlow/Keras.\n",
    "* Compare and contrast the two frameworks through small exploratory exercises."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175490fe",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Environment Setup\n",
    "\n",
    "Run the cell below to import the libraries used throughout this notebook. If you are running on a new environment, ensure that `torch`, `torchvision`, `tensorflow`, and `matplotlib` are installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1b728a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Reproducibility helpers\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"TensorFlow version: {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1957bf0",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Loading and Exploring the Dataset\n",
    "\n",
    "We will use the **Fashion-MNIST** dataset, which consists of 28x28 grayscale clothing images. Both PyTorch and TensorFlow provide convenient access to this dataset.\n",
    "\n",
    "> **Teaching tip:** Ask students to describe the normalization transform and explain why we apply it before training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8ff9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch dataset and dataloader\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "train_dataset = datasets.FashionMNIST(\n",
    "    root=\"./data\", train=True, download=True, transform=transform\n",
    ")\n",
    "test_dataset = datasets.FashionMNIST(\n",
    "    root=\"./data\", train=False, download=True, transform=transform\n",
    ")\n",
    "\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "class_names = train_dataset.classes\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08eb830a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visual inspection helper\n",
    "fig, axes = plt.subplots(2, 5, figsize=(12, 5))\n",
    "for ax in axes.ravel():\n",
    "    image, label = train_dataset[random.randint(0, len(train_dataset) - 1)]\n",
    "    ax.imshow(image.squeeze(), cmap=\"gray\")\n",
    "    ax.set_title(class_names[label])\n",
    "    ax.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e12bbc",
   "metadata": {},
   "source": [
    "### ðŸŽ¯ Exercise 1: Augmentation Exploration\n",
    "\n",
    "Try modifying the `transform` pipeline above to include data augmentation (e.g., random rotations or flips). Discuss how augmentation might affect model generalization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363c24ca",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. PyTorch Model\n",
    "\n",
    "Below is a lightweight CNN implemented in PyTorch. It trains quickly on CPU and is intentionally simple so that students can focus on understanding the workflow.\n",
    "\n",
    "> **Teaching prompt:** Pause after the model definition and ask learners to predict how many parameters are in each layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d702f0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TorchCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64 * 7 * 7, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "model_torch = TorchCNN()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model_torch.parameters(), lr=1e-3)\n",
    "model_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02601fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, dataloader, optimizer, criterion):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        preds = outputs.argmax(dim=1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    return running_loss / total, correct / total\n",
    "\n",
    "\n",
    "def evaluate(model, dataloader, criterion):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in dataloader:\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    return running_loss / total, correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b267cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 3\n",
    "for epoch in range(EPOCHS):\n",
    "    train_loss, train_acc = train_one_epoch(model_torch, train_loader, optimizer, criterion)\n",
    "    test_loss, test_acc = evaluate(model_torch, test_loader, criterion)\n",
    "    print(f\"Epoch {epoch + 1}: train_loss={train_loss:.4f}, train_acc={train_acc:.3f}, test_acc={test_acc:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17da278f",
   "metadata": {},
   "source": [
    "### ðŸŽ¯ Exercise 2: Optimizer Swap\n",
    "\n",
    "Ask students to replace the Adam optimizer with SGD (optionally with momentum) and observe how the training dynamics change. How does the convergence speed compare?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ada8201",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. TensorFlow / Keras Model\n",
    "\n",
    "We will now build a nearly identical architecture in TensorFlow using the Keras API. Highlight the parallels between the two frameworks and encourage students to identify similarities in layer configuration and training loops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac32c2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare TensorFlow datasets\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
    "\n",
    "# Normalize and add channel dimension\n",
    "x_train = (x_train / 255.0).astype(\"float32\")[..., np.newaxis]\n",
    "x_test = (x_test / 255.0).astype(\"float32\")[..., np.newaxis]\n",
    "\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(10000).batch(batch_size)\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(batch_size)\n",
    "\n",
    "label_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46090b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_model = keras.Sequential([\n",
    "    keras.layers.Conv2D(32, 3, padding=\"same\", activation=\"relu\", input_shape=(28, 28, 1)),\n",
    "    keras.layers.MaxPooling2D(),\n",
    "    keras.layers.Conv2D(64, 3, padding=\"same\", activation=\"relu\"),\n",
    "    keras.layers.MaxPooling2D(),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(128, activation=\"relu\"),\n",
    "    keras.layers.Dropout(0.3),\n",
    "    keras.layers.Dense(10)\n",
    "])\n",
    "\n",
    "loss_fn = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "tf_model.compile(optimizer=keras.optimizers.Adam(1e-3),\n",
    "                 loss=loss_fn,\n",
    "                 metrics=[\"accuracy\"])\n",
    "\n",
    "tf_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092d517f",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = tf_model.fit(train_ds, validation_data=test_ds, epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ed7041",
   "metadata": {},
   "source": [
    "### ðŸŽ¯ Exercise 3: Learning Rate Tuning\n",
    "\n",
    "Have learners adjust the learning rate in the `Adam` optimizer above. Encourage them to compare the resulting accuracy curves with the PyTorch model. Which framework made it easier to track metrics?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282184c7",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Comparing Predictions\n",
    "\n",
    "Finally, let's compare the predictions from both models on the same set of images. This helps students verify that similar architectures in different frameworks can achieve comparable performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d4652f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model_predictions(images, labels, torch_model, keras_model, n_samples=5):\n",
    "    torch_model.eval()\n",
    "    idxs = np.random.choice(len(images), size=n_samples, replace=False)\n",
    "\n",
    "    fig, axes = plt.subplots(n_samples, 3, figsize=(10, 2 * n_samples))\n",
    "    for row, idx in enumerate(idxs):\n",
    "        image = images[idx]\n",
    "        label = labels[idx]\n",
    "        axes[row, 0].imshow(image.squeeze(), cmap=\"gray\")\n",
    "        axes[row, 0].set_title(f\"True: {label_names[label]}\")\n",
    "        axes[row, 0].axis(\"off\")\n",
    "\n",
    "        with torch.no_grad():\n",
    "            torch_input = torch.tensor(image.transpose(2, 0, 1)).unsqueeze(0)\n",
    "            torch_logits = torch_model(torch_input)\n",
    "            torch_pred = torch_logits.argmax(dim=1).item()\n",
    "        axes[row, 1].barh(label_names, torch_logits.squeeze().softmax(dim=0).numpy())\n",
    "        axes[row, 1].set_title(f\"PyTorch Pred: {label_names[torch_pred]}\")\n",
    "\n",
    "        tf_logits = keras_model.predict(image[np.newaxis, ...], verbose=0)\n",
    "        tf_pred = tf_logits.argmax(axis=1)[0]\n",
    "        axes[row, 2].barh(label_names, tf.nn.softmax(tf_logits).numpy()[0])\n",
    "        axes[row, 2].set_title(f\"TensorFlow Pred: {label_names[tf_pred]}\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_model_predictions(x_test, y_test, model_torch, tf_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6851cea",
   "metadata": {},
   "source": [
    "### ðŸŽ¯ Exercise 4: Robustness Check\n",
    "\n",
    "Challenge students to craft a simple perturbation (e.g., adding noise) and evaluate how each model's predictions change. Which model is more robust to the perturbation?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b57906",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Wrap-Up Discussion\n",
    "\n",
    "* Summarize the similarities and differences between PyTorch and TensorFlow workflows.\n",
    "* Highlight how data input pipelines differ across frameworks.\n",
    "* Encourage students to consider when they might choose one framework over the other."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
