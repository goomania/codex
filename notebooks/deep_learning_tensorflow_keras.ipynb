{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ad6f945",
   "metadata": {},
   "source": [
    "# Deep Learning with TensorFlow and Keras\n",
    "\n",
    "This notebook introduces the key ideas behind deep learning using TensorFlow and Keras. We will train a convolutional neural network (CNN) from scratch and then demonstrate how to fine-tune a pre-trained model with transfer learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f2f4de",
   "metadata": {},
   "source": [
    "## Learning Objectives\n",
    "\n",
    "* Understand the building blocks of deep neural networks.\n",
    "* Learn how to prepare image data for training in TensorFlow.\n",
    "* Train a convolutional neural network (CNN) from scratch on the CIFAR-10 dataset.\n",
    "* Apply transfer learning with a pre-trained model and fine-tune it for improved performance.\n",
    "* Evaluate model performance with accuracy metrics and visualizations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1d7c9e",
   "metadata": {},
   "source": [
    "## Notebook Outline\n",
    "\n",
    "1. Introduction to Deep Learning Concepts\n",
    "2. Environment Setup\n",
    "3. Exploring the CIFAR-10 Dataset\n",
    "4. Building and Training a Baseline CNN\n",
    "5. Evaluating Model Performance\n",
    "6. Transfer Learning and Fine-Tuning with MobileNetV2\n",
    "7. Summary and Takeaways"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512d1de7",
   "metadata": {},
   "source": [
    "## 1. Introduction to Deep Learning Concepts\n",
    "\n",
    "Deep learning is a subset of machine learning that uses neural networks with many layers to learn complex patterns in data. Key ideas include:\n",
    "\n",
    "* **Neurons and Layers**: Each neuron computes a weighted sum of its inputs followed by a non-linear activation function. Layers of neurons compose to form deep networks.\n",
    "* **Feature Hierarchies**: Lower layers learn low-level features (e.g., edges in images), while higher layers learn more abstract concepts (e.g., object parts).\n",
    "* **Training with Backpropagation**: Networks learn parameters by minimizing a loss function using gradient descent and backpropagation.\n",
    "* **Regularization**: Techniques such as dropout, data augmentation, and weight decay prevent overfitting.\n",
    "* **Transfer Learning**: Pre-trained models can be fine-tuned on new tasks, reducing the amount of data and time needed to reach high accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb43cfc",
   "metadata": {},
   "source": [
    "## 2. Environment Setup\n",
    "\n",
    "We start by importing the Python packages required for the experiments. If you have access to a GPU, enabling it will accelerate training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa99f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(f'TensorFlow version: {tf.__version__}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27066f0",
   "metadata": {},
   "source": [
    "## 3. Exploring the CIFAR-10 Dataset\n",
    "\n",
    "The [CIFAR-10 dataset](https://www.cs.toronto.edu/~kriz/cifar.html) contains 60,000 color images (32x32 pixels) in 10 categories, with 6,000 images per class. TensorFlow provides a built-in loader that returns NumPy arrays for the training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc3d74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "print(f'Train images shape: {x_train.shape}')\n",
    "print(f'Test images shape: {x_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7cfa815",
   "metadata": {},
   "source": [
    "Let's visualize a few images to understand what the model will learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254dd082",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 4))\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i + 1)\n",
    "    plt.imshow(x_train[i])\n",
    "    plt.title(class_names[int(y_train[i])])\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34be357",
   "metadata": {},
   "source": [
    "### Data Preprocessing\n",
    "\n",
    "Neural networks converge faster when the input values are normalized. We will also convert the labels to integer vectors. For efficient training we use the `tf.data` API to batch and shuffle the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8714453c",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "num_classes = 10\n",
    "\n",
    "# Normalize pixel values to the [0, 1] range\n",
    "x_train_norm = x_train.astype('float32') / 255.0\n",
    "x_test_norm = x_test.astype('float32') / 255.0\n",
    "\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((x_train_norm, y_train))\n",
    "train_ds = train_ds.shuffle(buffer_size=len(x_train_norm)).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "val_split = 5000\n",
    "val_ds = tf.data.Dataset.from_tensor_slices((x_test_norm[:val_split], y_test[:val_split]))\n",
    "val_ds = val_ds.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((x_test_norm[val_split:], y_test[val_split:]))\n",
    "test_ds = test_ds.batch(batch_size).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18daddc5",
   "metadata": {},
   "source": [
    "## 4. Building and Training a Baseline CNN\n",
    "\n",
    "Convolutional neural networks are well-suited for image tasks. We will define a simple architecture with convolution, pooling, and dropout layers, followed by dense layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb431436",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_baseline_cnn():\n",
    "    model = models.Sequential([\n",
    "        layers.Input(shape=(32, 32, 3)),\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "        layers.MaxPooling2D(),\n",
    "        layers.Dropout(0.25),\n",
    "\n",
    "        layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "        layers.MaxPooling2D(),\n",
    "        layers.Dropout(0.3),\n",
    "\n",
    "        layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D(),\n",
    "        layers.Dropout(0.4),\n",
    "\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(256, activation='relu'),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(num_classes, activation='softmax'),\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "baseline_model = build_baseline_cnn()\n",
    "baseline_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081a112c",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b6acdf",
   "metadata": {},
   "source": [
    "### Training the Baseline Model\n",
    "\n",
    "We train for a handful of epochs to keep the runtime manageable. Increase the number of epochs for better accuracy if you have more compute time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59972fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "baseline_history = baseline_model.fit(\n",
    "    train_ds,\n",
    "    epochs=epochs,\n",
    "    validation_data=val_ds\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1756e17",
   "metadata": {},
   "source": [
    "### Evaluating the Baseline Model\n",
    "\n",
    "We visualize the training and validation curves and measure the final test accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee59c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history, title):\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history.get('val_accuracy')\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history.get('val_loss')\n",
    "\n",
    "    epochs_range = range(1, len(acc) + 1)\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "    if val_acc is not None:\n",
    "        plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "    plt.title(f'{title} Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs_range, loss, label='Training Loss')\n",
    "    if val_loss is not None:\n",
    "        plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "    plt.title(f'{title} Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "plot_history(baseline_history, title='Baseline CNN')\n",
    "\n",
    "baseline_test_loss, baseline_test_acc = baseline_model.evaluate(test_ds)\n",
    "print(f'Baseline CNN test accuracy: {baseline_test_acc:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03aa3e08",
   "metadata": {},
   "source": [
    "### Inspecting Predictions\n",
    "\n",
    "Let's take a quick look at how the model performs on individual samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa2c415",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_predictions(model, dataset, class_names, num_images=8):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    for images, labels in dataset.take(1):\n",
    "        preds = model.predict(images)\n",
    "        pred_labels = np.argmax(preds, axis=1)\n",
    "        for i in range(num_images):\n",
    "            plt.subplot(2, 4, i + 1)\n",
    "            plt.imshow(images[i])\n",
    "            true_label = class_names[int(labels[i])]\n",
    "            predicted_label = class_names[int(pred_labels[i])]\n",
    "            color = 'green' if true_label == predicted_label else 'red'\n",
    "            plt.title(f'True: {true_label}\n",
    "Pred: {predicted_label}', color=color)\n",
    "            plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "show_predictions(baseline_model, test_ds, class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b0b980",
   "metadata": {},
   "source": [
    "## 5. Transfer Learning and Fine-Tuning\n",
    "\n",
    "Training from scratch is powerful, but leveraging pre-trained models can yield better results faster. We will:\n",
    "\n",
    "1. Load a pre-trained MobileNetV2 model trained on ImageNet.\n",
    "2. Use it as a fixed feature extractor with frozen weights.\n",
    "3. Add a custom classification head for CIFAR-10.\n",
    "4. Fine-tune the top layers of the base model for additional gains."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c1fe52",
   "metadata": {},
   "source": [
    "### Preparing Data for Transfer Learning\n",
    "\n",
    "MobileNetV2 expects 160x160 pixel inputs with values in `[-1, 1]`. We will create a preprocessing pipeline that resizes and rescales the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f06a7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_size = (160, 160)\n",
    "preprocess_input = keras.applications.mobilenet_v2.preprocess_input\n",
    "\n",
    "resize_and_rescale = keras.Sequential([\n",
    "    layers.Resizing(target_size[0], target_size[1]),\n",
    "    layers.Lambda(preprocess_input),\n",
    "])\n",
    "\n",
    "augmented_train_ds = train_ds.map(\n",
    "    lambda x, y: (resize_and_rescale(x), y),\n",
    "    num_parallel_calls=tf.data.AUTOTUNE\n",
    ")\n",
    "augmented_val_ds = val_ds.map(\n",
    "    lambda x, y: (resize_and_rescale(x), y),\n",
    "    num_parallel_calls=tf.data.AUTOTUNE\n",
    ")\n",
    "augmented_test_ds = test_ds.map(\n",
    "    lambda x, y: (resize_and_rescale(x), y),\n",
    "    num_parallel_calls=tf.data.AUTOTUNE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99881821",
   "metadata": {},
   "source": [
    "### Building the Transfer Learning Model\n",
    "\n",
    "We combine the pre-trained MobileNetV2 base with a global pooling layer and a small dense head. Initially, the base model is frozen so only the new layers are trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab361c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = keras.applications.MobileNetV2(\n",
    "    input_shape=target_size + (3,),\n",
    "    include_top=False,\n",
    "    weights='imagenet'\n",
    ")\n",
    "base_model.trainable = False\n",
    "\n",
    "transfer_inputs = layers.Input(shape=target_size + (3,))\n",
    "x = base_model(transfer_inputs, training=False)\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dropout(0.2)(x)\n",
    "transfer_outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "transfer_model = keras.Model(inputs=transfer_inputs, outputs=transfer_outputs)\n",
    "transfer_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374d234c",
   "metadata": {},
   "outputs": [],
   "source": [
    "transfer_model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6a5db2",
   "metadata": {},
   "source": [
    "### Training the Feature Extractor\n",
    "\n",
    "We train only the new classification head while keeping the base model frozen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c221afd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "transfer_epochs = 5\n",
    "feature_history = transfer_model.fit(\n",
    "    augmented_train_ds,\n",
    "    epochs=transfer_epochs,\n",
    "    validation_data=augmented_val_ds\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50805f8",
   "metadata": {},
   "source": [
    "### Fine-Tuning the Top Layers\n",
    "\n",
    "Fine-tuning allows the model to adapt high-level representations to the CIFAR-10 dataset. We unfreeze a subset of layers and continue training with a lower learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0804d6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tune_at = 120\n",
    "for layer in base_model.layers[:fine_tune_at]:\n",
    "    layer.trainable = False\n",
    "for layer in base_model.layers[fine_tune_at:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "transfer_model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=1e-4),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "fine_tune_epochs = 5\n",
    "fine_tune_history = transfer_model.fit(\n",
    "    augmented_train_ds,\n",
    "    epochs=fine_tune_epochs,\n",
    "    validation_data=augmented_val_ds\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba14a55",
   "metadata": {},
   "source": [
    "### Evaluating Transfer Learning Performance\n",
    "\n",
    "We compare the learning curves and final accuracy against the baseline model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f9c201",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(feature_history, title='Transfer Learning (Frozen Base)')\n",
    "plot_history(fine_tune_history, title='Transfer Learning (Fine-Tuned)')\n",
    "\n",
    "transfer_test_loss, transfer_test_acc = transfer_model.evaluate(augmented_test_ds)\n",
    "print(f'Transfer learning model test accuracy: {transfer_test_acc:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "934f9aed",
   "metadata": {},
   "source": [
    "### Visualizing Transfer Learning Predictions\n",
    "\n",
    "Let's inspect predictions from the fine-tuned model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437c8bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_predictions(transfer_model, augmented_test_ds, class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f5bd412",
   "metadata": {},
   "source": [
    "## 6. Summary and Teaching Tips\n",
    "\n",
    "* **Baseline CNN**: Demonstrates the fundamentals of building and training a model from scratch. Encourage students to experiment with additional layers, different learning rates, or regularization techniques.\n",
    "* **Transfer Learning**: Shows how leveraging pre-trained models can quickly boost performance. Discuss how feature extraction and fine-tuning complement each other.\n",
    "* **Evaluation and Visualization**: Plots and sample predictions make the training process tangible for learners.\n",
    "\n",
    "### Suggested Classroom Activities\n",
    "\n",
    "1. **Hyperparameter Search**: Have students adjust the number of epochs, batch size, or optimizer and observe the effects on accuracy.\n",
    "2. **Data Augmentation Challenge**: Introduce `layers.RandomFlip`, `layers.RandomRotation`, or `layers.RandomZoom` in the preprocessing pipeline and compare results.\n",
    "3. **Model Comparison**: Swap MobileNetV2 for another architecture (e.g., EfficientNet, ResNet) and evaluate the trade-offs.\n",
    "4. **Real-World Discussion**: Connect model deployment considerations (latency, memory, fairness) to the models built in class."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
