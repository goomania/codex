{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92fbb8bd",
   "metadata": {},
   "source": [
    "# Computer Vision Mini Exercises — Answer Key\n",
    "\n",
    "This companion notebook provides worked solutions for the prompts in the *Computer Vision Mini Exercises* lesson. Each section mirrors the original activities and includes runnable code, suggested parameter choices, and short commentary you can use when reviewing answers with students."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4e10d1",
   "metadata": {},
   "source": [
    "## 1. Environment Setup\n",
    "\n",
    "We rely on the same libraries as the student notebook. Keeping the seeds fixed ensures our comparisons stay reproducible across frameworks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923dc8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"TensorFlow version: {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24239361",
   "metadata": {},
   "source": [
    "## 2. Dataset Loading with Augmentation (Exercise 1 Solution)\n",
    "\n",
    "To demonstrate a concrete augmentation pipeline, we chain together a gentle random rotation and horizontal flip before normalizing the Fashion-MNIST digits. Rotations of ±15° preserve the class identity while still encouraging rotational robustness. The augmented dataset plugs into the existing dataloaders without additional code changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226da60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\n",
    "    \"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\n",
    "    \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"\n",
    "]\n",
    "\n",
    "torch_transform = transforms.Compose([\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "train_dataset = datasets.FashionMNIST(\n",
    "    root=\"./data\", train=True, download=True, transform=torch_transform\n",
    ")\n",
    "test_dataset = datasets.FashionMNIST(\n",
    "    root=\"./data\", train=False, download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,))\n",
    "    ])\n",
    ")\n",
    "\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f829e2aa",
   "metadata": {},
   "source": [
    "### Visualizing Augmented Samples\n",
    "\n",
    "Plotting random training items makes the augmentation effects tangible and gives students an immediate sense of how rotations and flips manifest in Fashion-MNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9758632",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 5, figsize=(12, 5))\n",
    "for ax in axes.ravel():\n",
    "    image, label = train_dataset[random.randint(0, len(train_dataset) - 1)]\n",
    "    ax.imshow(image.squeeze(), cmap=\"gray\")\n",
    "    ax.set_title(class_names[label])\n",
    "    ax.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345eb52a",
   "metadata": {},
   "source": [
    "## 3. PyTorch Model and Optimizer Swap (Exercise 2 Solution)\n",
    "\n",
    "Switching from `Adam` to `SGD` with momentum highlights the effect of first-order versus adaptive optimizers. Using a slightly larger learning rate (0.05) and momentum (0.9) keeps convergence competitive while clearly illustrating the slower warm-up period that students observed in class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ffb31f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TorchCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64 * 7 * 7, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        return self.classifier(x)\n",
    "\n",
    "model_torch = TorchCNN()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model_torch.parameters(), lr=0.05, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad482580",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, dataloader, optimizer, criterion):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        preds = outputs.argmax(dim=1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    return running_loss / total, correct / total\n",
    "\n",
    "\n",
    "def evaluate(model, dataloader, criterion):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in dataloader:\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    return running_loss / total, correct / total\n",
    "\n",
    "EPOCHS = 3\n",
    "for epoch in range(EPOCHS):\n",
    "    train_loss, train_acc = train_one_epoch(model_torch, train_loader, optimizer, criterion)\n",
    "    test_loss, test_acc = evaluate(model_torch, test_loader, criterion)\n",
    "    print(f\"Epoch {epoch + 1}: train_loss={train_loss:.4f}, train_acc={train_acc:.3f}, test_loss={test_loss:.4f}, test_acc={test_acc:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd34c33f",
   "metadata": {},
   "source": [
    "**Instructor note:** Expect SGD to converge slightly slower than Adam in the first epoch, but by epoch three it typically reaches within ~1–2% accuracy of the adaptive baseline. Encourage students to discuss why the momentum term helps close the gap."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0daf78e",
   "metadata": {},
   "source": [
    "## 4. TensorFlow Model with Learning Rate Tuning (Exercise 3 Solution)\n",
    "\n",
    "A practical way to illustrate learning rate effects is to compile two models that differ only in their optimizer settings. The cell below demonstrates a moderately aggressive learning rate (0.005) that still trains stably, along with metric plots students can compare against the default 0.001 runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15080066",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
    "\n",
    "x_train = (x_train / 255.0).astype(\"float32\")[..., np.newaxis]\n",
    "x_test = (x_test / 255.0).astype(\"float32\")[..., np.newaxis]\n",
    "\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(10000, seed=SEED).batch(batch_size)\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa78c3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tf_model():\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Conv2D(32, 3, padding=\"same\", activation=\"relu\", input_shape=(28, 28, 1)),\n",
    "        keras.layers.MaxPooling2D(),\n",
    "        keras.layers.Conv2D(64, 3, padding=\"same\", activation=\"relu\"),\n",
    "        keras.layers.MaxPooling2D(),\n",
    "        keras.layers.Flatten(),\n",
    "        keras.layers.Dense(128, activation=\"relu\"),\n",
    "        keras.layers.Dropout(0.3),\n",
    "        keras.layers.Dense(10)\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "lr_tuned_model = build_tf_model()\n",
    "lr_tuned_model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.005),\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5a41c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = lr_tuned_model.fit(train_ds, validation_data=test_ds, epochs=3)\n",
    "\n",
    "plt.figure(figsize=(8, 3))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history[\"loss\"], label=\"train\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"val\")\n",
    "plt.title(\"Loss\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history[\"accuracy\"], label=\"train\")\n",
    "plt.plot(history.history[\"val_accuracy\"], label=\"val\")\n",
    "plt.title(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ff4bd6",
   "metadata": {},
   "source": [
    "**Instructor note:** If the higher learning rate destabilizes training on some machines, drop it to 0.003 and point out that TensorFlow's callback visualizations make these trade-offs easy to monitor live."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8038eb",
   "metadata": {},
   "source": [
    "## 5. Cross-Framework Prediction Comparison (Exercise 4 Solution)\n",
    "\n",
    "To evaluate robustness, we add Gaussian noise to a shared batch of test images and compare how each model's predictions change. The helper below reports accuracy before and after perturbation and plots a few representative examples for discussion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb55bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def torch_infer(model, dataset):\n",
    "    model.eval()\n",
    "    all_images = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in DataLoader(dataset, batch_size=batch_size):\n",
    "            all_images.append(images)\n",
    "            all_labels.append(labels)\n",
    "    return torch.cat(all_images), torch.cat(all_labels)\n",
    "\n",
    "\n",
    "def evaluate_with_noise(torch_model, keras_model, noise_std=0.25, n_samples=5):\n",
    "    torch_images, torch_labels = torch_infer(torch_model, test_dataset)\n",
    "    baseline_logits = torch_model(torch_images)\n",
    "    baseline_acc = (baseline_logits.argmax(dim=1) == torch_labels).float().mean().item()\n",
    "\n",
    "    noisy_images = torch_images + noise_std * torch.randn_like(torch_images)\n",
    "    noisy_images = torch.clamp(noisy_images, -1.0, 1.0)\n",
    "    noisy_logits = torch_model(noisy_images)\n",
    "    noisy_acc = (noisy_logits.argmax(dim=1) == torch_labels).float().mean().item()\n",
    "\n",
    "    tf_images = x_test[:len(torch_images)]\n",
    "    tf_logits = keras_model.predict(tf_images, verbose=0)\n",
    "    tf_preds = tf_logits.argmax(axis=1)\n",
    "    tf_acc = (tf_preds == y_test[:len(torch_images)]).mean()\n",
    "\n",
    "    tf_noisy = np.clip(tf_images + noise_std * np.random.normal(size=tf_images.shape), 0.0, 1.0)\n",
    "    tf_noisy_logits = keras_model.predict(tf_noisy, verbose=0)\n",
    "    tf_noisy_preds = tf_noisy_logits.argmax(axis=1)\n",
    "    tf_noisy_acc = (tf_noisy_preds == y_test[:len(torch_images)]).mean()\n",
    "\n",
    "    print(f\"Torch accuracy: clean={baseline_acc:.3f}, noisy={noisy_acc:.3f}\")\n",
    "    print(f\"TensorFlow accuracy: clean={tf_acc:.3f}, noisy={tf_noisy_acc:.3f}\")\n",
    "\n",
    "    idxs = np.random.choice(len(torch_images), size=n_samples, replace=False)\n",
    "    fig, axes = plt.subplots(n_samples, 3, figsize=(10, 2 * n_samples))\n",
    "    for row, idx in enumerate(idxs):\n",
    "        axes[row, 0].imshow(torch_images[idx].squeeze(), cmap=\"gray\")\n",
    "        axes[row, 0].set_title(f\"Label: {class_names[torch_labels[idx]]}\")\n",
    "        axes[row, 0].axis(\"off\")\n",
    "\n",
    "        axes[row, 1].imshow(noisy_images[idx].squeeze(), cmap=\"gray\")\n",
    "        axes[row, 1].set_title(\"Torch noisy\")\n",
    "        axes[row, 1].axis(\"off\")\n",
    "\n",
    "        axes[row, 2].imshow(tf_noisy[idx].squeeze(), cmap=\"gray\")\n",
    "        axes[row, 2].set_title(\"TF noisy\")\n",
    "        axes[row, 2].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Run once both models have been trained\n",
    "# evaluate_with_noise(model_torch, lr_tuned_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200efac7",
   "metadata": {},
   "source": [
    "### Wrap-Up Notes\n",
    "\n",
    "* Reinforce that similar architectural choices across frameworks yield comparable performance once hyperparameters are tuned appropriately.\n",
    "* Encourage learners to iterate on the augmentation parameters and learning rates to explore the robustness/accuracy trade-off further."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
