{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# Stock Market Data Collection, Modeling, and Analysis (CRISP-DM)\n\nThis notebook is designed as an end-to-end, **educational** example for students to practice data science with real-world financial data. It follows the **CRISP-DM framework**:\n\n1. **Business Understanding**\n2. **Data Understanding**\n3. **Data Preparation**\n4. **Modeling**\n5. **Evaluation**\n6. **Deployment**\n\n> **Disclaimer:** This notebook is for learning purposes only and **not** financial advice."
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 1. Business Understanding\n\n**Goal:** Build a repeatable workflow to collect stock data, compute trading-relevant statistics (returns, volatility, moving averages, RSI, MACD), and train a simple predictive model for **next-day returns**.\n\n**Key questions:**\n- How can we collect open, high, low, close, volume, and engineered features?\n- Which statistics are commonly used to inform trading decisions?\n- How can we evaluate model performance for time-series data?"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 2. Data Understanding\n\nWe will use **Yahoo Finance** data via the `yfinance` package (no API key required).\n\n> **Note:** In production, you might use paid APIs (Polygon, Alpha Vantage, IEX Cloud) for higher reliability and limits. Those typically require API keys."
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "# If needed in your environment, uncomment the line below to install yfinance.\n# !pip -q install yfinance\n\n# Import core libraries for data collection and analysis.\nimport pandas as pd\nimport numpy as np\nimport yfinance as yf\nimport matplotlib.pyplot as plt\n\n# Configure plotting for readability in notebooks.\nplt.style.use(\"seaborn-v0_8\")",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "# Define the stock tickers and date range for analysis.\n# You can edit this list to explore other stocks or ETFs.\ntickers = [\"AAPL\", \"MSFT\", \"AMZN\", \"GOOGL\", \"TSLA\"]\nstart_date = \"2018-01-01\"\nend_date = \"2024-01-01\"\n\n# Download daily OHLCV (Open, High, Low, Close, Volume) data for all tickers.\n# The result is a multi-index column DataFrame.\nraw_data = yf.download(tickers, start=start_date, end=end_date, group_by=\"ticker\", auto_adjust=False)\n\n# Display the first few rows to understand the structure.\nraw_data.head()",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "# Let's inspect the available fields for one ticker (AAPL).\n# This helps students understand how the data is organized.\nraw_data[\"AAPL\"].head()",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 3. Data Preparation\n\nWe will reshape the data, calculate **daily returns**, **moving averages**, **rolling volatility**, **RSI**, and **MACD**, which are common technical indicators."
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "# Extract the 'Close' prices into a clean DataFrame with tickers as columns.\nclose_prices = pd.DataFrame({ticker: raw_data[ticker][\"Close\"] for ticker in tickers})\n\n# Calculate daily returns (percentage change) for each ticker.\nreturns = close_prices.pct_change().dropna()\n\n# Preview the processed datasets.\nclose_prices.head(), returns.head()",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "# Define helper functions for RSI and MACD to keep our code clean and reusable.\ndef compute_rsi(series, window=14):\n    \"\"\"Compute the Relative Strength Index (RSI) for a price series.\"\"\"\n    # Calculate price changes\n    delta = series.diff()\n    # Separate positive and negative gains\n    gain = delta.where(delta > 0, 0.0)\n    loss = -delta.where(delta < 0, 0.0)\n    # Compute average gains and losses\n    avg_gain = gain.rolling(window=window).mean()\n    avg_loss = loss.rolling(window=window).mean()\n    # Prevent division by zero\n    rs = avg_gain / avg_loss.replace(0, np.nan)\n    # Convert to RSI\n    rsi = 100 - (100 / (1 + rs))\n    return rsi\n\n\ndef compute_macd(series, fast=12, slow=26, signal=9):\n    \"\"\"Compute MACD line and signal line for a price series.\"\"\"\n    # Exponential moving averages for fast and slow windows\n    ema_fast = series.ewm(span=fast, adjust=False).mean()\n    ema_slow = series.ewm(span=slow, adjust=False).mean()\n    # MACD line is the difference\n    macd_line = ema_fast - ema_slow\n    # Signal line is the EMA of the MACD line\n    signal_line = macd_line.ewm(span=signal, adjust=False).mean()\n    return macd_line, signal_line",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "# Build a feature dataset for a single ticker to simplify modeling.\n# You can loop over tickers later as a student exercise.\n\nticker = \"AAPL\"\nprices = raw_data[ticker][\"Close\"].copy()\n\n# Create a DataFrame for features and target.\ndata = pd.DataFrame({\"close\": prices})\n\n# Add daily returns.\ndata[\"return\"] = data[\"close\"].pct_change()\n\n# Add simple moving averages (SMA) for short and long windows.\ndata[\"sma_20\"] = data[\"close\"].rolling(window=20).mean()\ndata[\"sma_50\"] = data[\"close\"].rolling(window=50).mean()\n\n# Add rolling volatility (standard deviation of returns).\ndata[\"volatility_20\"] = data[\"return\"].rolling(window=20).std()\n\n# Add RSI and MACD indicators.\ndata[\"rsi_14\"] = compute_rsi(data[\"close\"], window=14)\nmacd_line, signal_line = compute_macd(data[\"close\"], fast=12, slow=26, signal=9)\ndata[\"macd\"] = macd_line\ndata[\"macd_signal\"] = signal_line\n\n# Define the prediction target: next-day return.\ndata[\"target_return\"] = data[\"return\"].shift(-1)\n\n# Remove rows with missing values caused by rolling windows.\ndata = data.dropna()\n\n# Inspect feature set.\ndata.head()",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 4. Modeling\n\nWe will train a simple model to predict **next-day return** using the engineered features.\nThis is **not** a production trading system—just a learning example."
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "# Import machine learning tools from scikit-learn.\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n\n# Select features and target for modeling.\nfeature_cols = [\"return\", \"sma_20\", \"sma_50\", \"volatility_20\", \"rsi_14\", \"macd\", \"macd_signal\"]\nX = data[feature_cols]\ny = data[\"target_return\"]\n\n# Use a time-based split (no shuffling) for realistic evaluation.\n# Here, we take the first 80% as training and the last 20% as testing.\nsplit_index = int(len(data) * 0.8)\nX_train, X_test = X.iloc[:split_index], X.iloc[split_index:]\ny_train, y_test = y.iloc[:split_index], y.iloc[split_index:]\n\n# Train a simple linear regression model.\nmodel = LinearRegression()\nmodel.fit(X_train, y_train)\n\n# Make predictions on the test set.\ny_pred = model.predict(X_test)",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 5. Evaluation\n\nWe evaluate model performance using **MAE**, **RMSE**, and **R²**. For time-series, you should also visually inspect predictions and residuals."
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "# Compute evaluation metrics.\nmae = mean_absolute_error(y_test, y_pred)\nmse = mean_squared_error(y_test, y_pred)\nrmse = np.sqrt(mse)\nr2 = r2_score(y_test, y_pred)\n\n# Display metrics in a readable format.\nprint(f\"MAE:  {mae:.6f}\")\nprint(f\"RMSE: {rmse:.6f}\")\nprint(f\"R²:   {r2:.6f}\")",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "# Plot actual vs. predicted next-day returns.\nplt.figure(figsize=(12, 4))\nplt.plot(y_test.index, y_test, label=\"Actual\", alpha=0.7)\nplt.plot(y_test.index, y_pred, label=\"Predicted\", alpha=0.7)\nplt.title(f\"{ticker} Next-Day Return: Actual vs Predicted\")\nplt.xlabel(\"Date\")\nplt.ylabel(\"Return\")\nplt.legend()\nplt.show()",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 6. Deployment (Educational Example)\n\nIn a real project, you might save your trained model and create a pipeline to refresh data daily.\nHere, we show how to serialize the model using `joblib`."
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "# If needed, install joblib. (Often comes with scikit-learn.)\n# !pip -q install joblib\n\nimport joblib\n\n# Save the trained model to disk.\nmodel_path = \"linear_return_model.joblib\"\njoblib.dump(model, model_path)\n\n# Load the model back (to verify saving worked).\nloaded_model = joblib.load(model_path)\n\n# Quick sanity check: predictions from the loaded model should match.\nloaded_pred = loaded_model.predict(X_test)\nnp.allclose(y_pred, loaded_pred)",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Extension Ideas (Student Exercises)\n\n1. **Multi-ticker modeling:** Loop through `tickers` and compare metrics.\n2. **Alternative models:** Try RandomForestRegressor, GradientBoostingRegressor, or XGBoost.\n3. **Feature engineering:** Add volume-based indicators (OBV, VWAP).\n4. **Backtesting:** Create a simple strategy based on model signals and evaluate returns.\n5. **API exploration:** Replace `yfinance` with another API using authentication keys."
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "---\n\n### Quick Discussion Questions\n\n- Why might next-day return prediction be difficult?\n- How do moving averages help smooth noisy financial data?\n- What risks arise from training on historical prices?"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}