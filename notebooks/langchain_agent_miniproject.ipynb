{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99f2319e",
   "metadata": {},
   "source": [
    "\n",
    "# LangChain Agent Mini-Project\n",
    "\n",
    "This notebook walks through building a simple research assistant agent with [LangChain](https://python.langchain.com). It is designed for hands-on classroom demos and runs in Google Colab.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00073171",
   "metadata": {},
   "source": [
    "\n",
    "## Project Overview\n",
    "\n",
    "We will:\n",
    "\n",
    "1. Install the dependencies that Colab needs for LangChain.\n",
    "2. Explore the idea of tool-using agents and configure a Wikipedia search tool.\n",
    "3. Build a ReAct-style agent that decides when to query Wikipedia and when to answer directly.\n",
    "4. Run the agent with either a real OpenAI chat model (for live demos) or a built-in fake model (for offline/test runs).\n",
    "5. Package helper utilities so your class can experiment with their own questions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2366cd8",
   "metadata": {},
   "source": [
    "\n",
    "> **Tip for instructors:** The notebook defaults to a self-contained fake model so that it runs without external API keys. To use a real LLM on Colab, set the `OPENAI_API_KEY` environment variable (or edit the configuration cell) and switch the `USE_FAKE_MODEL` flag to `False`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072da32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you are running this in Colab, execute this cell once to install dependencies.\n",
    "# On Colab this takes ~1 minute. Locally you may comment this out if packages already exist.\n",
    "!pip install -qU \"langchain==0.1.20\" \"langchain-community==0.0.38\" \"langchain-openai==0.1.7\" wikipedia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39be7ff8",
   "metadata": {},
   "source": [
    "\n",
    "## 1. Imports and configuration\n",
    "\n",
    "We toggle between a fake model (great for automated tests or offline runs) and an OpenAI chat model. The fake model replies with pre-scripted ReAct traces so the rest of the workflow behaves exactly like a live demo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5fdd30",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "\n",
    "USE_FAKE_MODEL = os.environ.get(\"USE_FAKE_LANGCHAIN_MODEL\", \"True\").lower() in {\"1\", \"true\", \"yes\", \"on\"}\n",
    "print(f\"Using fake model: {USE_FAKE_MODEL}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c928a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_FAKE_MODEL:\n",
    "    from langchain_community.chat_models import FakeListChatModel\n",
    "\n",
    "    fake_plan = \"\"\"Thought: I should check the Wikipedia tool for background information.\n",
    "Action: Wikipedia\n",
    "Action Input: LangChain\"\"\"\n",
    "    fake_summary = \"\"\"Thought: I can answer the question now that I have context.\n",
    "Final Answer: LangChain was created by Harrison Chase to help developers build agents and other LLM-powered applications by combining prompts, tools, and memory.\"\"\"\n",
    "\n",
    "    llm = FakeListChatModel(responses=[fake_plan, fake_summary])\n",
    "else:\n",
    "    from langchain_openai import ChatOpenAI\n",
    "\n",
    "    if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "        raise ValueError(\"OPENAI_API_KEY is not set. Either provide a key or keep USE_FAKE_MODEL enabled.\")\n",
    "\n",
    "    llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "llm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729005a9",
   "metadata": {},
   "source": [
    "\n",
    "## 2. Define tools the agent can use\n",
    "\n",
    "We'll use LangChain's Wikipedia integration so the agent can look up facts. Tools can wrap APIs, local functions, or other chains. The agent will decide when to call the tool.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9c9f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "from langchain_core.tools import Tool\n",
    "\n",
    "if USE_FAKE_MODEL:\n",
    "    SAMPLE_WIKI_SNIPPETS: Dict[str, str] = {\n",
    "        \"langchain\": (\n",
    "            \"LangChain is an open-source framework created by Harrison Chase that helps developers build applications \"\n",
    "            \"powered by large language models (LLMs). It focuses on orchestrating prompts, tools, memory, and agents.\"\n",
    "        ),\n",
    "        \"harrison chase\": (\n",
    "            \"Harrison Chase is the CEO and co-founder of LangChain. Prior to LangChain he worked on robotics and applied AI \"\n",
    "            \"projects, and created the framework to simplify building LLM agents.\"\n",
    "        ),\n",
    "    }\n",
    "\n",
    "    def offline_wikipedia(query: str) -> str:\n",
    "        key = query.strip().lower()\n",
    "        for term, blurb in SAMPLE_WIKI_SNIPPETS.items():\n",
    "            if term in key:\n",
    "                return blurb\n",
    "        return (\n",
    "            \"Offline demo mode: pretend we looked this up on Wikipedia. \"\n",
    "            \"LangChain streamlines connecting LLMs with tools so they can reason and act.\"\n",
    "        )\n",
    "\n",
    "    wikipedia_tool = Tool(\n",
    "        name=\"Wikipedia\",\n",
    "        func=offline_wikipedia,\n",
    "        description=\"Offline-friendly Wikipedia lookup for well-known AI topics.\"\n",
    "    )\n",
    "else:\n",
    "    from langchain_community.utilities import WikipediaAPIWrapper\n",
    "    from langchain_community.tools import WikipediaQueryRun\n",
    "\n",
    "    wikipedia = WikipediaAPIWrapper(lang=\"en\", top_k_results=1, doc_content_chars_max=2000)\n",
    "\n",
    "    wikipedia_tool = Tool(\n",
    "        name=\"Wikipedia\",\n",
    "        func=WikipediaQueryRun(api_wrapper=wikipedia).run,\n",
    "        description=\"Useful for researching well-known topics or people by querying Wikipedia.\"\n",
    "    )\n",
    "\n",
    "TOOLS = [wikipedia_tool]\n",
    "print(\"Configured tools:\")\n",
    "for tool in TOOLS:\n",
    "    print(f\"- {tool.name}: {tool.description}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb97fc9",
   "metadata": {},
   "source": [
    "\n",
    "## 3. Create a ReAct-style agent\n",
    "\n",
    "LangChain's `initialize_agent` helper wires the model and tools together. The ReAct (Reasoning + Acting) agent type alternates between reasoning steps (\"Thought\") and tool usage (\"Action\"/\"Observation\").\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098aa665",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain.agents import AgentType, initialize_agent\n",
    "\n",
    "agent_executor = initialize_agent(\n",
    "    tools=TOOLS,\n",
    "    llm=llm,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "agent_executor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dec775a",
   "metadata": {},
   "source": [
    "\n",
    "## 4. Run the agent on a demo question\n",
    "\n",
    "By default, the fake model produces a deterministic trace so you can narrate each step. When using a real OpenAI key, the agent will reach out to Wikipedia live and craft a new answer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f23746",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_question = \"Who created LangChain and why is it useful for building AI agents?\"\n",
    "result = agent_executor.invoke({\"input\": demo_question})\n",
    "\n",
    "print(\"Final answer:\", result[\"output\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ba612e",
   "metadata": {},
   "source": [
    "\n",
    "## 5. Helper function for interactive exploration\n",
    "\n",
    "Use `run_agent` to let students supply their own questions. When `USE_FAKE_MODEL` is `True`, the function replays the deterministic trace. Flip the flag (and set your API key) for live responses.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adebf8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_agent(question: str) -> str:\n",
    "    '''Run the LangChain agent and return the final answer.'''\n",
    "    response = agent_executor.invoke({\"input\": question})\n",
    "    return response[\"output\"]\n",
    "\n",
    "# Example usage (feel free to edit the question):\n",
    "run_agent(\"What problem does LangChain solve for developers?\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea5c3ac",
   "metadata": {},
   "source": [
    "\n",
    "## 6. Wrap-up ideas for class discussion\n",
    "\n",
    "* Ask students to add another tool (e.g., a calculator or a news API) and observe how the agent behaves.\n",
    "* Compare the deterministic fake trace with real OpenAI outputs to highlight the role of the LLM.\n",
    "* Discuss guardrails: what instructions could we add to the system prompt to keep the agent focused on class-safe content?\n",
    "\n",
    "Happy teaching!\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
