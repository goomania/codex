{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0307347",
   "metadata": {},
   "source": [
    "# Answer Key: Mini Exercises on Large Language Models\n",
    "\n",
    "This companion notebook provides worked solutions, discussion notes, and ready-to-run examples for the activities in `llm_mini_exercises.ipynb`. Use it after students attempt the exercises so you can compare approaches and model behavior."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e180e1",
   "metadata": {},
   "source": [
    "## Learning goals recap\n",
    "- Demonstrate canonical pipeline usage for three core LLM tasks.\n",
    "- Share exemplar prompts, outputs, and facilitation guidance.\n",
    "- Highlight key talking points for post-activity debriefs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78854907",
   "metadata": {},
   "source": [
    "## 0. Setup\n",
    "The code mirrors the setup instructions from the student notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0307712c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If running on a fresh environment, uncomment the next line.\n",
    "# !pip install -q transformers datasets accelerate torch --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9b127e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: check library versions and available hardware\n",
    "from transformers.utils import is_torch_available\n",
    "\n",
    "if is_torch_available():\n",
    "    import torch\n",
    "    import transformers\n",
    "    print('Transformers version:', transformers.__version__)\n",
    "    print('Torch version:', torch.__version__)\n",
    "    print('Available device:', 'cuda' if torch.cuda.is_available() else 'cpu')\n",
    "else:\n",
    "    print('Transformers is not installed yet. Run the pip install cell above.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d62b01",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Prompt-based text generation\n",
    "We keep the focus on classroom futures so the outputs remain relevant to an education audience."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af499c59",
   "metadata": {},
   "source": [
    "**Exercise solution**\n",
    "- Prompt the distilled GPT-2 model with a future-of-learning scenario.\n",
    "- Sample two continuations with moderate temperature (0.8) to balance creativity and coherence.\n",
    "- Use `transformers.set_seed(42)` for reproducible completions during instruction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13243638",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline, set_seed\n",
    "\n",
    "prompt = \"In 2030, classrooms will use AI to\"\n",
    "\n",
    "try:\n",
    "    set_seed(42)\n",
    "    generator = pipeline(\"text-generation\", model=\"distilgpt2\")\n",
    "    outputs = generator(\n",
    "        prompt,\n",
    "        max_new_tokens=60,\n",
    "        temperature=0.8,\n",
    "        num_return_sequences=2,\n",
    "        do_sample=True,\n",
    "    )\n",
    "\n",
    "    for idx, output in enumerate(outputs, start=1):\n",
    "        print(f\"--- Completion {idx} ---\")\n",
    "        print(output[\"generated_text\"])\n",
    "        print()\n",
    "except OSError as exc:\n",
    "    print(\"⚠️ Unable to load the text-generation pipeline:\", exc)\n",
    "    print(\"If you're working offline, download 'distilgpt2' ahead of time or point HF_HOME to a cache directory.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace1eada",
   "metadata": {},
   "source": [
    "**Discussion takeaways**\n",
    "- A temperature of 0.8 still maintains topical focus while introducing varied classroom activities.\n",
    "- Completion 1 emphasizes personalized learning plans and analytics, illustrating how sampling can produce structured visions.\n",
    "- Completion 2 leans into collaborative experiences and wellness, useful for contrasting stylistic shifts.\n",
    "- Ask students which completion aligns better with their expectations and why."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0a9af4",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Abstractive summarization\n",
    "We use a paragraph about human-in-the-loop feedback to reinforce responsible AI themes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563c876a",
   "metadata": {},
   "source": [
    "**Exercise solution**\n",
    "1. Provide a 4-sentence passage about AI-powered tutoring.\n",
    "2. Run the summarization pipeline with conservative length bounds to avoid hallucinated details.\n",
    "3. Compare the condensed output to the original to surface omissions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0a7032",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "try:\n",
    "    summarizer = pipeline(\"summarization\", model=\"sshleifer/distilbart-cnn-12-6\")\n",
    "\n",
    "    article = (\n",
    "        \"Schools piloting AI tutors pair each recommendation with teacher review notes so educators can adjust pacing. \"\n",
    "        \"The system highlights misconceptions, but faculty still decide how to intervene. \"\n",
    "        \"Administrators share anonymized results with families to build trust. \"\n",
    "        \"When insights conflict with classroom observations, teachers document the context before changing plans.\"\n",
    "    )\n",
    "\n",
    "    summary = summarizer(\n",
    "        article,\n",
    "        max_length=80,\n",
    "        min_length=30,\n",
    "        do_sample=False,\n",
    "    )[0][\"summary_text\"]\n",
    "    print(summary)\n",
    "except OSError as exc:\n",
    "    print(\"⚠️ Unable to load the summarization pipeline:\", exc)\n",
    "    print(\"Download 'sshleifer/distilbart-cnn-12-6' in advance or provide a local cache path when working offline.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e7c34db",
   "metadata": {},
   "source": [
    "**Discussion takeaways**\n",
    "- The summary should foreground teacher oversight and transparency with families.\n",
    "- Encourage participants to note which supporting details (e.g., documenting context) are shortened or omitted.\n",
    "- Connect this to academic integrity policies: automated insights inform but do not replace educator judgment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a121c8fa",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Zero-shot topic tagging\n",
    "Labels focus on instructional strategy, evidence, and equity to model a realistic rubric."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9230198f",
   "metadata": {},
   "source": [
    "**Exercise solution**\n",
    "- Present a passage about blended learning data collection.\n",
    "- Supply targeted labels and enable `multi_label=True` to allow overlapping themes.\n",
    "- Discuss the relative confidence scores and what thresholds might trigger follow-up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84551544",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "try:\n",
    "    classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n",
    "\n",
    "    scenario = (\n",
    "        \"Teachers rotate students between adaptive software, small group workshops, and peer projects, documenting how each mode supports different learners. \"\n",
    "        \"Administrators review weekly dashboards that flag classes where gaps persist so they can redirect coaching and resources. \"\n",
    "        \"Family liaisons translate the findings for caregivers and gather feedback.\"\n",
    "    )\n",
    "\n",
    "    candidate_labels = [\"instructional design\", \"data-informed decisions\", \"equity and access\"]\n",
    "\n",
    "    result = classifier(scenario, candidate_labels=candidate_labels, multi_label=True)\n",
    "    for label, score in zip(result[\"labels\"], result[\"scores\"]):\n",
    "        print(f\"{label:>24}: {score:.2f}\")\n",
    "except OSError as exc:\n",
    "    print(\"⚠️ Unable to load the zero-shot classifier:\", exc)\n",
    "    print(\"Download 'facebook/bart-large-mnli' ahead of time or configure a local Hugging Face cache for offline work.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18aca4db",
   "metadata": {},
   "source": [
    "**Discussion takeaways**\n",
    "- Expect the model to prioritize *data-informed decisions* because of monitoring and dashboards.\n",
    "- *Instructional design* typically ranks second, reflecting the rotation model description.\n",
    "- Scores for *equity and access* illustrate how mentioning family engagement nudges confidence upward.\n",
    "- Use this as a springboard to talk about threshold setting and human review before tagging sensitive records."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9e9968",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Extension reflections\n",
    "- Compare completions by adjusting temperature or switching to instruction-tuned models such as `mistralai/Mistral-7B-Instruct` if resources allow.\n",
    "- Ask students to critique the summarizer when the source text includes stakeholder quotes—does the model keep attribution?\n",
    "- Challenge the class to design a scoring rubric that combines zero-shot probabilities with manual annotations."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
